{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPtr3t7cSTiFa6GiMTmOJcM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NamrataKamani07/NLP/blob/main/NLP_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2uFsmfeC-DM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpMYNe0WEaM0"
      },
      "source": [
        "Tokenize the given text into sentences and words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4n5dziFhEbYk",
        "outputId": "acbbbff0-0d69-4b10-9f36-87d481b22438"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from urllib import request\n",
        "from __future__ import division\n",
        "import nltk, re, pprint\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dXd8hd1FIXK"
      },
      "source": [
        "text = \"Coursera Inc. (/kərˈsɛrə/) is an American massive open online course provider founded in 2012 by \" + \\\n",
        "       \"Stanford University computer science professors Andrew Ng and Daphne Koller. Coursera works \" + \\\n",
        "       \"with universities and other organizations to offer online courses, certifications, and degrees in a  \" + \\\n",
        "       \"ariety of subjects. According to CNBC more than 150 universities offered upwards of 4,000\" + \\\n",
        "       \"courses through Coursera, which features over two dozen degree programs at prices that are lower than many in-person school offerings \""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAgNjqhaF_91",
        "outputId": "19e16fc7-c4c8-46d1-fc42-02df98604067"
      },
      "source": [
        "print(sent_tokenize(text))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Coursera Inc. (/kərˈsɛrə/) is an American massive open online course provider founded in 2012 by Stanford University computer science professors Andrew Ng and Daphne Koller.', 'Coursera works with universities and other organizations to offer online courses, certifications, and degrees in a  ariety of subjects.', 'According to CNBC more than 150 universities offered upwards of 4,000courses through Coursera, which features over two dozen degree programs at prices that are lower than many in-person school offerings']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qmb06nlRGCC9",
        "outputId": "6cc3698d-92a5-4fba-c890-67dbadddb8ac"
      },
      "source": [
        "print(word_tokenize(text))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Coursera', 'Inc.', '(', '/kərˈsɛrə/', ')', 'is', 'an', 'American', 'massive', 'open', 'online', 'course', 'provider', 'founded', 'in', '2012', 'by', 'Stanford', 'University', 'computer', 'science', 'professors', 'Andrew', 'Ng', 'and', 'Daphne', 'Koller', '.', 'Coursera', 'works', 'with', 'universities', 'and', 'other', 'organizations', 'to', 'offer', 'online', 'courses', ',', 'certifications', ',', 'and', 'degrees', 'in', 'a', 'ariety', 'of', 'subjects', '.', 'According', 'to', 'CNBC', 'more', 'than', '150', 'universities', 'offered', 'upwards', 'of', '4,000courses', 'through', 'Coursera', ',', 'which', 'features', 'over', 'two', 'dozen', 'degree', 'programs', 'at', 'prices', 'that', 'are', 'lower', 'than', 'many', 'in-person', 'school', 'offerings']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B10MCos9G9aW"
      },
      "source": [
        "Pos tag each word to display its grammatical information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZbK8KTBHAnt",
        "outputId": "d783126b-bb96-4d1b-881e-34023134b294"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "from nltk import CFG\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk import pos_tag\n",
        "from tkinter import *\n",
        "\n",
        "# convert text into word_tokens with their tags\n",
        "def pos_tagging(text):\n",
        "    word_tokens = word_tokenize(text)\n",
        "    return pos_tag(word_tokens)\n",
        "    \n",
        "pos_tagging('Coursera Inc. (/kərˈsɛrə/) is an American massive open online course provider founded in 2012 by Stanford University computer science professors Andrew Ng and Daphne Koller. Coursera works with universities and other organizations to offer online courses, certifications, and degrees in a variety of subjects. According to CNBC \"more than 150 universities offered upwards of 4,000 courses through Coursera, which features over two dozen degree programs at prices that are lower than many in-person school offerings.')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Coursera', 'NNP'),\n",
              " ('Inc.', 'NNP'),\n",
              " ('(', '('),\n",
              " ('/kərˈsɛrə/', 'NNP'),\n",
              " (')', ')'),\n",
              " ('is', 'VBZ'),\n",
              " ('an', 'DT'),\n",
              " ('American', 'JJ'),\n",
              " ('massive', 'JJ'),\n",
              " ('open', 'JJ'),\n",
              " ('online', 'NN'),\n",
              " ('course', 'NN'),\n",
              " ('provider', 'NN'),\n",
              " ('founded', 'VBN'),\n",
              " ('in', 'IN'),\n",
              " ('2012', 'CD'),\n",
              " ('by', 'IN'),\n",
              " ('Stanford', 'NNP'),\n",
              " ('University', 'NNP'),\n",
              " ('computer', 'NN'),\n",
              " ('science', 'NN'),\n",
              " ('professors', 'NNS'),\n",
              " ('Andrew', 'NNP'),\n",
              " ('Ng', 'NNP'),\n",
              " ('and', 'CC'),\n",
              " ('Daphne', 'NNP'),\n",
              " ('Koller', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Coursera', 'NNP'),\n",
              " ('works', 'VBZ'),\n",
              " ('with', 'IN'),\n",
              " ('universities', 'NNS'),\n",
              " ('and', 'CC'),\n",
              " ('other', 'JJ'),\n",
              " ('organizations', 'NNS'),\n",
              " ('to', 'TO'),\n",
              " ('offer', 'VB'),\n",
              " ('online', 'JJ'),\n",
              " ('courses', 'NNS'),\n",
              " (',', ','),\n",
              " ('certifications', 'NNS'),\n",
              " (',', ','),\n",
              " ('and', 'CC'),\n",
              " ('degrees', 'NNS'),\n",
              " ('in', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('variety', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('subjects', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('According', 'VBG'),\n",
              " ('to', 'TO'),\n",
              " ('CNBC', 'NNP'),\n",
              " ('``', '``'),\n",
              " ('more', 'JJR'),\n",
              " ('than', 'IN'),\n",
              " ('150', 'CD'),\n",
              " ('universities', 'NNS'),\n",
              " ('offered', 'VBN'),\n",
              " ('upwards', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('4,000', 'CD'),\n",
              " ('courses', 'NNS'),\n",
              " ('through', 'IN'),\n",
              " ('Coursera', 'NNP'),\n",
              " (',', ','),\n",
              " ('which', 'WDT'),\n",
              " ('features', 'VBZ'),\n",
              " ('over', 'IN'),\n",
              " ('two', 'CD'),\n",
              " ('dozen', 'NN'),\n",
              " ('degree', 'NN'),\n",
              " ('programs', 'NNS'),\n",
              " ('at', 'IN'),\n",
              " ('prices', 'NNS'),\n",
              " ('that', 'WDT'),\n",
              " ('are', 'VBP'),\n",
              " ('lower', 'JJR'),\n",
              " ('than', 'IN'),\n",
              " ('many', 'JJ'),\n",
              " ('in-person', 'JJ'),\n",
              " ('school', 'NN'),\n",
              " ('offerings', 'NNS'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMOeL7oZISn4"
      },
      "source": [
        "Apply chunking to extract the following sentence from the given text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVqS3yOtIWn0",
        "outputId": "94502f84-08b6-4a34-b8c6-e1baf7870964"
      },
      "source": [
        "from nltk.tree import *\n",
        "from collections import defaultdict\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk import pos_tag\n",
        "  \n",
        "# define chunking function with text and regular\n",
        "# expression representing grammar as parameter\n",
        "def chunking(text, grammar):\n",
        "    word_tokens = word_tokenize(text)\n",
        "  \n",
        "    # label words with part of speech\n",
        "    word_pos = pos_tag(word_tokens)\n",
        "  \n",
        "    # create a chunk parser using grammar\n",
        "    chunkParser = nltk.RegexpParser(grammar)\n",
        "  \n",
        "    # test it on the list of word tokens with tagged pos\n",
        "    tree = chunkParser.parse(word_pos)\n",
        "\n",
        "    for subtree in tree.subtrees():\n",
        "        print(subtree)\n",
        "    \n",
        "      \n",
        "sentence = 'Coursera works with universities and other organizations to offer online courses, certifications, and degrees in a variety of subjects'\n",
        "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
        "chunking(sentence, grammar)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  Coursera/NNP\n",
            "  works/VBZ\n",
            "  with/IN\n",
            "  universities/NNS\n",
            "  and/CC\n",
            "  other/JJ\n",
            "  organizations/NNS\n",
            "  to/TO\n",
            "  offer/VB\n",
            "  online/JJ\n",
            "  courses/NNS\n",
            "  ,/,\n",
            "  certifications/NNS\n",
            "  ,/,\n",
            "  and/CC\n",
            "  degrees/NNS\n",
            "  in/IN\n",
            "  (NP a/DT variety/NN)\n",
            "  of/IN\n",
            "  subjects/NNS)\n",
            "(NP a/DT variety/NN)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLfEnlsWJrjH"
      },
      "source": [
        "After chunking (Q. 4), POS tag the sentence and search for the information about programs Courses, certifications and  degrees using POS taggers and Regular Expression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OPPGguhJxVw",
        "outputId": "2c483238-421c-49d7-e8f0-bc5840c39379"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "from nltk import CFG\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk import pos_tag\n",
        "from tkinter import *\n",
        "\n",
        "# convert text into word_tokens with their tags\n",
        "def pos_tagging(text):\n",
        "    word_tokens = word_tokenize(text)\n",
        "    return pos_tag(word_tokens)\n",
        "    \n",
        "pos_tagging('Coursera works with universities and other organizations to offer online courses, certifications, and degrees in a variety of subjects')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Coursera', 'NNP'),\n",
              " ('works', 'VBZ'),\n",
              " ('with', 'IN'),\n",
              " ('universities', 'NNS'),\n",
              " ('and', 'CC'),\n",
              " ('other', 'JJ'),\n",
              " ('organizations', 'NNS'),\n",
              " ('to', 'TO'),\n",
              " ('offer', 'VB'),\n",
              " ('online', 'JJ'),\n",
              " ('courses', 'NNS'),\n",
              " (',', ','),\n",
              " ('certifications', 'NNS'),\n",
              " (',', ','),\n",
              " ('and', 'CC'),\n",
              " ('degrees', 'NNS'),\n",
              " ('in', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('variety', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('subjects', 'NNS')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhHa8oz2Kqmt",
        "outputId": "b3ca43a4-7055-4908-c149-4b8ca05c8995"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "  \n",
        "tokenizer = RegexpTokenizer(\"[\\w']+\")\n",
        "text = \"Coursera works with universities and other organizations to offer online courses, certifications, and degrees in a variety of subjects\"\n",
        "tokenizer.tokenize(text)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Coursera',\n",
              " 'works',\n",
              " 'with',\n",
              " 'universities',\n",
              " 'and',\n",
              " 'other',\n",
              " 'organizations',\n",
              " 'to',\n",
              " 'offer',\n",
              " 'online',\n",
              " 'courses',\n",
              " 'certifications',\n",
              " 'and',\n",
              " 'degrees',\n",
              " 'in',\n",
              " 'a',\n",
              " 'variety',\n",
              " 'of',\n",
              " 'subjects']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSWJ8858K1ae"
      },
      "source": [
        "Display the parser tree for the Noun Phrase for the chunk derived in Q. 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DXwYd3oK2ct",
        "outputId": "fef63caf-ce7b-4d66-8f4d-fd9477a02806"
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import pos_tag, word_tokenize, RegexpParser\n",
        "   \n",
        "# Example text\n",
        "sample_text = \"Coursera works with universities and other organizations to offer online courses, certifications, and degrees in a variety of subjects\"\n",
        "   \n",
        "# Find all parts of speech in above sentence\n",
        "tagged = pos_tag(word_tokenize(sample_text))\n",
        "   \n",
        "#Extract all parts of speech from any text\n",
        "chunker = RegexpParser(\"\"\"\n",
        "                       NP: {<DT>?<JJ>*<NN>}    #To extract Noun Phrases\n",
        "                       P: {<IN>}               #To extract Prepositions\n",
        "                       V: {<V.*>}              #To extract Verbs\n",
        "                       PP: {<P> <NP>}          #To extract Prepostional Phrases\n",
        "                       VP: {<V> <NP|PP>*}      #To extarct Verb Phrases\n",
        "                       \"\"\")\n",
        "  \n",
        "# Print all parts of speech in above sentence\n",
        "output = chunker.parse(tagged)\n",
        "print(\"After Extracting\\n\", output)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "After Extracting\n",
            " (S\n",
            "  Coursera/NNP\n",
            "  (VP (V works/VBZ))\n",
            "  (P with/IN)\n",
            "  universities/NNS\n",
            "  and/CC\n",
            "  other/JJ\n",
            "  organizations/NNS\n",
            "  to/TO\n",
            "  (VP (V offer/VB))\n",
            "  online/JJ\n",
            "  courses/NNS\n",
            "  ,/,\n",
            "  certifications/NNS\n",
            "  ,/,\n",
            "  and/CC\n",
            "  degrees/NNS\n",
            "  (PP (P in/IN) (NP a/DT variety/NN))\n",
            "  (P of/IN)\n",
            "  subjects/NNS)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSm4RgJjPsY5"
      },
      "source": [
        "Get the Bog of words for the given text and display the word with its frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHBMgeO7Pu6E"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "import numpy as np\n",
        "  \n",
        "# execute the text here as :\n",
        "text = \"Coursera works with universities and other organizations to offer online courses, certifications, and degrees in a variety of subjects\"\n",
        "dataset = nltk.sent_tokenize(text)\n",
        "for i in range(len(dataset)):\n",
        "    dataset[i] = dataset[i].lower()\n",
        "    dataset[i] = re.sub(r'\\W', ' ', dataset[i])\n",
        "    dataset[i] = re.sub(r'\\s+', ' ', dataset[i])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfHqPpDxP2B1"
      },
      "source": [
        "# Creating the Bag of Words model\n",
        "word2count = {}\n",
        "for data in dataset:\n",
        "    words = nltk.word_tokenize(data)\n",
        "    for word in words:\n",
        "        if word not in word2count.keys():\n",
        "            word2count[word] = 1\n",
        "        else:\n",
        "            word2count[word] += 1"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDruBs5FReoi"
      },
      "source": [
        "Find the synonym and antonym of words ‘found’ and ‘organization’."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoefntafRfVR",
        "outputId": "1de0661c-01bc-47e2-c469-5520e7f8dd70"
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "syns = wordnet.synsets(\"program\")\n",
        "print(syns[0].name())\n",
        "print(syns[0].lemmas()[0].name())\n",
        "print(syns[0].definition())\n",
        "print(syns[0].examples())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "plan.n.01\n",
            "plan\n",
            "a series of steps to be carried out or goals to be accomplished\n",
            "['they drew up a six-step plan', 'they discussed plans for a new bond issue']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAkYi82hRsSY",
        "outputId": "c07d9c54-aef2-4370-b0e6-5f810d1c611e"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "synonyms = []\n",
        "antonyms = []\n",
        "  \n",
        "for syn in wordnet.synsets(\"found\"):\n",
        "    for l in syn.lemmas():\n",
        "        synonyms.append(l.name())\n",
        "        if l.antonyms():\n",
        "            antonyms.append(l.antonyms()[0].name())\n",
        "  \n",
        "print(set(synonyms))\n",
        "print(set(antonyms))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'plant', 'find_oneself', 'establish', 'find_out', 'regain', 'detect', 'base', 'happen', 'institute', 'found', 'chance', 'line_up', 'get_hold', 'discover', 'launch', 'ground', 'encounter', 'retrieve', 'observe', 'obtain', 'determine', 'bump', 'find', 'constitute', 'notice', 'witness', 'incur', 'get', 'set_up', 'see', 'come_up', 'rule', 'ascertain', 'feel', 'receive', 'recover'}\n",
            "{'abolish', 'lost', 'lose'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q62x7HCCRw89",
        "outputId": "e4e6203c-2cce-47d3-a02c-8619881fa064"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "synonyms = []\n",
        "antonyms = []\n",
        "  \n",
        "for syn in wordnet.synsets(\"organization\"):\n",
        "    for l in syn.lemmas():\n",
        "        synonyms.append(l.name())\n",
        "        if l.antonyms():\n",
        "            antonyms.append(l.antonyms()[0].name())\n",
        "  \n",
        "print(set(synonyms))\n",
        "print(set(antonyms))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'administration', 'system', 'constitution', 'governance', 'organisation', 'organization', 'brass', 'governing_body', 'arrangement', 'formation', 'establishment'}\n",
            "set()\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}